# -*- coding: utf-8 -*-
"""layer-8-label-3-190088H.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/108R72Q55ZpwPB2DtSt_4-IRa28GIHnyR
"""



!python3 -m pip install -U matplotlib
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import sklearn as sk
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier

def train_and_evaluate_models(X_train, y_train, X_val, y_val):
    """
    Train and evaluate multiple classification models on the given data.

    Parameters:
    - X_train: Training features
    - y_train: Training labels
    - X_val: Validation features
    - y_val: Validation labels

    Returns:
    - A dictionary containing model names as keys and their accuracies on the validation data as values.
    """

    models = {
#         'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
        'SVM': SVC(kernel='linear', C=1.0, random_state=42),
        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
        'Logistic Regression_abraham': LogisticRegression(max_iter=1000, random_state=42,solver='lbfgs'),
        'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),
#         'Naive Bayes': GaussianNB(),
#         'Decision Tree': DecisionTreeClassifier(random_state=42)
    }

    accuracies = {}

    for model_name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_val)
        accuracy = accuracy_score(y_val, y_pred)
        accuracies[model_name] = accuracy
    print(accuracies)
    return accuracies

# cross validation using different models

from sklearn.model_selection import cross_val_score, KFold
def cross_validation(x_train,y_train,x_valid,y_valid):
    classifiers = [
    ("Random Forest", RandomForestClassifier()),
    ('Logistic Regression',LogisticRegression(max_iter=1000, random_state=42)),
    ("K-Nearest Neighbors", KNeighborsClassifier(n_neighbors=5)),
    ("SVM", SVC(kernel="linear"))]



    for model_name, model in classifiers:
        cross_val_scores = cross_val_score(model, x_train, y_train, cv=5)
        print(f"{model_name} Cross-validation scores:", cross_val_scores)
        print(f"{model_name} Mean accuracy:", cross_val_scores.mean())
        print(f"{model_name} Standard deviation:", cross_val_scores.std())
        print("\n")

#function for knn model using and check accuarcy

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
def knn(train_x,train_y,valid_x,valid_y):
    model = RandomForestClassifier(n_estimators=100)
    model.fit(train_x, train_y)
    y_pred = model.predict(valid_x)
    accuracy = accuracy_score(valid_y, y_pred)
    print(f'Accuracy using knn: {accuracy:.2f}')

#function for data preprocessing
from sklearn.preprocessing import StandardScaler
def preprocessing(label):
    train=pd.read_csv("train.csv")
    test=pd.read_csv("test.csv")
    valid=pd.read_csv("valid.csv")
    train_x_label_1=train.iloc[:, :-4]
    train_y_label_1=train.iloc[:,-5+label]


    valid_x_label_1=train.iloc[:, :-4]
    valid_y_label_1=train.iloc[:,-5+label]

    test_x_label_1=train.iloc[:, 1:]

    ss = StandardScaler()
    scaled_train_x_label = ss.fit_transform(train_x_label_1)
    scaled_train_x_label
    scaled_test_x_label=ss.fit_transform(test_x_label_1)
    scaled_valid_x_label=ss.fit_transform(valid_x_label_1)
    return scaled_train_x_label,scaled_valid_x_label

# scaling function
from sklearn.preprocessing import StandardScaler
def scale(train_x,valid_x,test_x):
    ss = StandardScaler()
    scaled_train_x_label = ss.fit_transform(train_x)
    scaled_train_x_label
    scaled_test_x_label=ss.fit_transform(test_x)
    scaled_valid_x_label=ss.fit_transform(valid_x)
    return scaled_train_x_label,scaled_valid_x_label

# pca approch
from sklearn.decomposition import PCA
def pca(train_x,train_y,valid_x,valid_y,test_x):
    pca=PCA(.95, svd_solver='full')
    pca=pca.fit(train_x)
    train_features_pca=pca.transform(train_x)
    valid_features_pca=pca.transform(valid_x)
    test_features_pca=pca.transform(test_x)
    print("accuarcy after pca")
    #     knn(train_features_pca,train_y,valid_features_pca,valid_y)
    return train_features_pca,valid_features_pca,test_features_pca

# Write predicted values to a CSV file.
import pandas as pd

def write_predictions_to_csv(predictions, output_file):


    # Create a DataFrame with a column for predictions
    df = pd.DataFrame({'Predicted_Label': predictions})

    # Save the DataFrame to a CSV file
    df.to_csv(output_file, index=False)  # Set index=False to exclude row numbers

train=pd.read_csv("/kaggle/input/ml-grp-project-layer-11/train.csv")
test=pd.read_csv("/kaggle/input/ml-grp-project-layer-11/test.csv")
valid=pd.read_csv("/kaggle/input/ml-grp-project-layer-11/valid.csv")

train.head()

test.head()

valid.head()

train.info()

train.dtypes

#Check is there any NaN values

train.isnull().sum()

#check is there any duplicates in the data set
train.drop_duplicates()


#only label_2 has NaN values

#cheack is there any string values, if there any string values we can encode the values.
contains_strings=train.applymap(lambda x: isinstance(x, str))
if contains_strings.any().any():
    print("There are string values in the DataFrame columns.")
else:
    print("There are no string values in the DataFrame columns.")

"""label 3

"""

train_x_label_1=train.iloc[:, :-4]
train_y_label_1=train.iloc[:,-2:-1]
valid_x_label_1=valid.iloc[:, :-4]
valid_y_label_1=valid.iloc[:,-2:-1]
test_x_label_1=test.iloc[:, 1:]
train_x_label_1
test_x_label_1

# knn(train_x_label_1,train_y_label_1,valid_x_label_1,valid_y_label_1)
# Accuracy using knn: 0.97

#check duplicates
train_features_T = train_x_label_1.T
train_features_T.shape
print(train_features_T.duplicated().sum())

train_y_label_1

import matplotlib.pyplot as plt
plt.hist(train_y_label_1['label_3'], bins=10, edgecolor='k')  # Adjust the number of bins as needed
plt.xlabel('label 3 values')
plt.ylabel('Frequency')
plt.title('Frequency Distribution of Target Values')
plt.grid(True)

# Show the plot
plt.show()

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
scaled_train_x_label_1 = ss.fit_transform(train_x_label_1)
scaled_train_x_label_1
scaled_test_x_label_1=ss.fit_transform(test_x_label_1)
scaled_valid_x_label_1=ss.fit_transform(valid_x_label_1)
print(scaled_train_x_label_1.shape,scaled_test_x_label_1.shape,scaled_valid_x_label_1.shape)

#feature selection
from sklearn.feature_selection import f_classif
from sklearn.feature_selection import SelectKBest
from sklearn.model_selection import GridSearchCV
# Create a SelectKBest instance with a scoring function (e.g., chi-squared)
selector = SelectKBest(score_func=f_classif, k=400)  # Select the top 2 features

# Fit and transform your data to select the best k features
scaled_train_x_label_2_df = selector.fit_transform(scaled_train_x_label_1, train_y_label_1)
scaled_valid_x_label_2_df = selector.transform(scaled_valid_x_label_1)
scaled_test_x_label_2_df = selector.transform(scaled_test_x_label_1)

scaled_train_x_label_1_df = pd.DataFrame(scaled_train_x_label_1,columns = train_x_label_1.columns)
scaled_train_x_label_1_df.describe()
scaled_test_x_label_1_df=pd.DataFrame(scaled_test_x_label_1,columns=test_x_label_1.columns)
scaled_valid_x_label_1_df=pd.DataFrame(scaled_valid_x_label_1,columns=valid_x_label_1.columns)

scaled_train_x_label_1_df.describe()

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split



model = RandomForestClassifier(n_estimators=100)
model.fit(scaled_train_x_label_1, train_y_label_1)
y_pred = model.predict(scaled_valid_x_label_1_df)
from sklearn.metrics import accuracy_score

# Calculate the accuracy
accuracy = accuracy_score(valid_y_label_1, y_pred)
print(f'Accuracy: {accuracy:.2f}')



correlated_features = set()
correlation_matrix = scaled_train_x_label_1_df.corr()
# print(correlation_matrix)
for i in range(len(correlation_matrix .columns)):
    for j in range(i):
        if abs(correlation_matrix.iloc[i, j]) > 0.5:
            colname = correlation_matrix.columns[i]
            correlated_features.add(colname)
# print(correlated_features)
scaled_train_x_label_1_df.drop(labels=correlated_features, axis=1, inplace=True)
scaled_valid_x_label_1_df.drop(labels=correlated_features, axis=1, inplace=True)
scaled_test_x_label_1_df.drop(labels=correlated_features, axis=1, inplace=True)

print(scaled_train_x_label_1_df.shape,scaled_test_x_label_1_df.shape,scaled_valid_x_label_1_df)
# knn(scaled_train_x_label_1_df,train_y_label_1,scaled_valid_x_label_1_df,valid_y_label_1)
#accuracy removing features 0.86

train_and_evaluate_models(scaled_train_x_label_1_df,train_y_label_1,scaled_valid_x_label_1_df,valid_y_label_1)

print("Before pca accuaracy")

# use pca
# pca(scaled_train_x_label_1_df,train_y_label_1,scaled_valid_x_label_1_df,valid_y_label_1)

scaled_train_x_label_1_df_pca,scaled_valid_x_label_1_df_pca,scaled_test_x_label_1_df_pca=pca(scaled_train_x_label_1_df,train_y_label_1,scaled_valid_x_label_1_df,valid_y_label_1,scaled_test_x_label_1_df)

print("after PCA")
train_and_evaluate_models(scaled_train_x_label_1_df_pca,train_y_label_1,scaled_valid_x_label_1_df_pca,valid_y_label_1)

from sklearn.linear_model import LogisticRegression
model=LogisticRegression(max_iter=1000, random_state=42)
model.fit(scaled_train_x_label_1_df_pca,train_y_label_1)
y_pred = model.predict(scaled_valid_x_label_1_df_pca)
print(y_pred)
y_pred_test= model.predict(scaled_test_x_label_1_df_pca)
print(y_pred_test)

write_predictions_to_csv(y_pred_test, "label_3_test_logistic_regression_predictions_with_hyperameter_tuning.csv")

# hyper parameter tuninng
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression

# Define hyperparameter grid
param_grid = {
    'C': [ 1, 10, 100],  # Adjust the range based on your needs
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear', 'lbfgs'],
#     'max_iter': [100, 200, 300]  # Adjust the range based on your needs
}

# Create a Logistic Regression classifier
logistic_regression = LogisticRegression()

# Perform Grid Search with cross-validation (e.g., 5-fold cross-validation)
grid_search = GridSearchCV(estimator=logistic_regression, param_grid=param_grid, scoring='accuracy', cv=5)

# Fit the Grid Search to your training data
grid_search.fit(scaled_train_x_label_1_df_pca,train_y_label_1)

# Get the best hyperparameters
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Get the best model
best_model = grid_search.best_estimator_

# Evaluate the best model on the validation data
accuracy = best_model.score(scaled_valid_x_label_1_df_pca, valid_y_label_1)
print("Validation Accuracy with Best Model:", accuracy)
y_pred= best_model.predict(scaled_valid_x_label_1_df_pca)
y_test_pred=best_model.predict(scaled_test_x_label_1_df_pca)

# Best Hyperparameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}
# Validation Accuracy with Best Model: 0.992
# write to the csv file
write_predictions_to_csv(y_pred, "layer_11_label_3_logistic_regression_predictions_with_hyperameter_tuning.csv")
write_predictions_to_csv(y_test_pred,"layer_11_label_3_logistic_regression_predictions_with_hyperparameter_tuing.csv")

y_pred

# hyper parameter tuning for svm
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC


# Define the parameter grid for hyperparameter tuning
param_grid = {
    'C': [0.1, 1, 10, 100],
    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']
}

# Create the SVC classifier
svc = SVC()

# Perform grid search cross-validation
grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, n_jobs=-1)
grid_search.fit(scaled_train_x_label_1_df_pca,train_y_label_1)

# Print the best hyperparameters and score
print("Best Hyperparameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)

# Evaluate the tuned model on the test dataset
best_svc = grid_search.best_estimator_
accuracy = best_svc.score(scaled_valid_x_label_1_df_pca, valid_y_label_1)
print("Validation Accuracy with Best Model:", accuracy)
y_pred= best_svc.predict(scaled_valid_x_label_1_df_pca)
y_pred_test= best_svc.predict(scaled_test_x_label_1_df_pca)
print(best_svc)

# Best Hyperparameters: {'C': 10, 'kernel': 'rbf'}
# Best Score: 0.9869565217391305
# Validation Accuracy with Best Model: 0.9973333333333333
# SVC(C=10)
write_predictions_to_csv(y_pred, "layer_11_label_3_svc_with_hyperameter_tuning.csv")
write_predictions_to_csv(y_test_pred, "layer_11_label_3_test_data_svc_with_hyperameter_tuning.csv")